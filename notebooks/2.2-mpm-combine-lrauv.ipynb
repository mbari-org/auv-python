{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot combined variables against original data \n",
    "To run this Notebook follow instructions at https://github.com/mbari-org/auv-python.\n",
    "\n",
    "Processed files must be available locally. Execute `uv run src/data/process_lrauv.py` with the `--no_cleanup` option to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src/data'));\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import netCDF4 as nc4\n",
    "import logging\n",
    "from nc42netcdfs import BASE_LRAUV_PATH\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Change to logging.DEBUG for more detailed output\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Enable bokeh extension for hvplot\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Get time coordinate for each variable by introspection\n",
    "def get_time_coord(var):\n",
    "    \"\"\"Get the time coordinate name for a variable.\n",
    "    \n",
    "    Args:\n",
    "        var: Either an xarray.DataArray or netCDF4.Variable\n",
    "        \n",
    "    Returns:\n",
    "        str: Name of the time coordinate/dimension\n",
    "    \"\"\"\n",
    "    # Check if it's an xarray DataArray (has .dims attribute)\n",
    "    if hasattr(var, 'dims'):\n",
    "        # xarray DataArray\n",
    "        time_dims = [dim for dim in var.dims if 'time' in dim.lower()]\n",
    "        return time_dims[0] if time_dims else var.dims[0]\n",
    "    elif hasattr(var, 'dimensions'):\n",
    "        # netCDF4 Variable\n",
    "        time_dims = [dim for dim in var.dimensions if 'time' in dim.lower()]\n",
    "        return time_dims[0] if time_dims else var.dimensions[0]\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported variable type: {type(var)}\")\n",
    "\n",
    "# Pick the auv_name\n",
    "auv_name = widgets.Dropdown(\n",
    "    options=[f for f in sorted(os.listdir(BASE_LRAUV_PATH)) if f != \".DS_Store\"],\n",
    "    description='auv_name:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(auv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the log file from the selected LRAUV directory\n",
    "# Pattern: {lrauv_name}/missionlogs/{year}/{date_range}/{mission_start}/{log_file}.nc4\n",
    "\n",
    "lrauv_name = auv_name.value\n",
    "log_files = sorted(Path(BASE_LRAUV_PATH).glob(f\"{lrauv_name}/missionlogs/*/*/*/*[0-9].nc4\"))\n",
    "log_file_options = [str(f.relative_to(BASE_LRAUV_PATH)) for f in log_files]\n",
    "\n",
    "log_file_picker = widgets.Select(\n",
    "    options=log_file_options,\n",
    "    description='Log File:',\n",
    "    disabled=False,\n",
    "    rows=15,\n",
    "    layout=widgets.Layout(width='800px')\n",
    ")\n",
    "display(log_file_picker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all Group .nc files produced by nc42netcdfs.py for the selected log file\n",
    "log_file = log_file_picker.value\n",
    "log_path = Path(BASE_LRAUV_PATH) / log_file\n",
    "log_stem = log_path.stem\n",
    "log_dir = log_path.parent\n",
    "\n",
    "# Pattern: {log_stem}_Group_{GroupName}.nc\n",
    "group_files = sorted(log_dir.glob(f\"{log_stem}_Group_*.nc\"))\n",
    "\n",
    "# Create dictionary keyed by original group name\n",
    "group_file_dict = {}\n",
    "for group_file in group_files:\n",
    "    # Extract group name from filename: {log_stem}_Group_{GroupName}.nc\n",
    "    group_name = group_file.stem.split(\"_Group_\")[1]\n",
    "    group_file_dict[group_name] = group_file\n",
    "\n",
    "logger.debug(f\"Found {len(group_file_dict)} extracted group files for {log_file}:\")\n",
    "for group_name, file_path in sorted(group_file_dict.items()):\n",
    "    logger.debug(f\"  {group_name} -> {file_path.name}\")\n",
    "\n",
    "# Read the log_file and the corresponding combined netCDF files into xarray Datasets\n",
    "combined_file = log_file.replace('.nc4', '_combined.nc4')\n",
    "\n",
    "# Open log file with all groups\n",
    "log_nc = nc4.Dataset(os.path.join(BASE_LRAUV_PATH, log_file))\n",
    "logger.debug(\"Log file: \" + os.path.join(BASE_LRAUV_PATH, log_file))\n",
    "log_ds = xr.open_dataset(os.path.join(BASE_LRAUV_PATH, log_file))\n",
    "\n",
    "# Show root group details only in DEBUG mode\n",
    "if logger.isEnabledFor(logging.DEBUG):\n",
    "    logger.debug(\"Only root group (universals):\")\n",
    "    display(log_ds)\n",
    "\n",
    "# Create dictionary mapping converted group names to original group names\n",
    "# Conversion logic from combine.py: remove underscores and lowercase\n",
    "group_name_mapping = {\n",
    "    group.replace(\"_\", \"\").lower(): group\n",
    "    for group in log_nc.groups.keys()\n",
    "}\n",
    "logger.debug(\"Group name mapping (converted -> original) with extracted NetCDF3 file listed underneath.\")\n",
    "logger.debug(\"File is created for items put into the SCIENG_PARMS group in the nc42netcdfs.py script: \")\n",
    "logger.debug(\"\")\n",
    "for converted, original in sorted(group_name_mapping.items()):\n",
    "    logger.debug(f\"{converted} -> {original}\")\n",
    "    if original in group_file_dict:\n",
    "        logger.debug(f\"File: {group_file_dict[original]}\")\n",
    "logger.debug(\"\")\n",
    "\n",
    "combined_ds = xr.open_dataset(os.path.join(BASE_LRAUV_PATH, combined_file))\n",
    "\n",
    "# Show combined dataset details only in DEBUG mode\n",
    "if logger.isEnabledFor(logging.DEBUG):\n",
    "    logger.debug(\"\\nCombined file: \" + os.path.join(BASE_LRAUV_PATH, combined_file))\n",
    "    display(combined_ds)\n",
    "\n",
    "def plot_original_vs_combined(variable_name):\n",
    "    \"\"\"Plot a variable from both original group and combined file overlaid.\n",
    "    \n",
    "    Args:\n",
    "        variable_name: Name of the variable from combined dataset (format: {group}_{variable})\n",
    "        \n",
    "    Returns:\n",
    "        Overlay plot of original and combined data\n",
    "    \"\"\"\n",
    "    # Parse variable name to extract converted group name and original variable name\n",
    "    # Format: {converted_group}_{original_variable}\n",
    "    parts = variable_name.split('_', 1)\n",
    "    converted_group = parts[0]\n",
    "    original_var = parts[1] if len(parts) > 1 else variable_name\n",
    "\n",
    "    # Map back to original group name\n",
    "    original_group = group_name_mapping.get(converted_group, converted_group)\n",
    "\n",
    "    logger.debug(f\"Processing variable: {variable_name}\")\n",
    "    logger.debug(f\"Converted group: {converted_group}, Original group: {original_group}\")\n",
    "\n",
    "    # Get the original group dataset from log_nc\n",
    "    # Root group (universals) is accessed directly as log_nc, not through .groups\n",
    "    if original_group == \"universals\":\n",
    "        group_ds = log_nc\n",
    "    else:\n",
    "        group_ds = log_nc.groups[original_group]\n",
    "\n",
    "    # Find the original variable from the group in log_file ignoring case\n",
    "    original_var_lower = original_var.lower()\n",
    "    matching_vars = [var for var in group_ds.variables if var.lower() == original_var_lower]\n",
    "    if matching_vars:\n",
    "        original_var = matching_vars[0]\n",
    "    logger.debug(f\"Original variable: {original_var}\")\n",
    "\n",
    "    logger.debug(f\"Plotting '{original_var}' from group '{original_group}' vs combined variable '{variable_name}'\")\n",
    "\n",
    "    # Get time coordinates\n",
    "    original_time_coord = get_time_coord(group_ds.variables[original_var])\n",
    "    combined_time_coord = get_time_coord(combined_ds[variable_name])\n",
    "    logger.debug(f\"Time coords - Original: {original_time_coord}, Combined: {combined_time_coord}\")\n",
    "\n",
    "    # Extract data from netCDF4 as numpy arrays\n",
    "    original_time_data = group_ds.variables[original_time_coord][:]\n",
    "    original_var_data = group_ds.variables[original_var][:]\n",
    "    logger.debug(f\"Data shape - Original: {original_var_data.shape}, time: {original_time_data.shape}\")\n",
    "\n",
    "    # Convert Unix timestamps to datetime64 to match combined file format\n",
    "    original_time_datetime = pd.to_datetime(original_time_data, unit='s')\n",
    "    original_series = pd.Series(original_var_data, index=original_time_datetime, name=f'{original_var} (Original)')\n",
    "\n",
    "    # Get units for ylabel\n",
    "    try:\n",
    "        original_units = group_ds.variables[original_var].getncattr('units')\n",
    "    except AttributeError:\n",
    "        original_units = ''\n",
    "    \n",
    "    try:\n",
    "        combined_units = combined_ds[variable_name].attrs.get('units', '')\n",
    "    except (AttributeError, KeyError):\n",
    "        combined_units = ''\n",
    "    \n",
    "    # Create ylabel with format \"name (units)\"\n",
    "    ylabel = f\"{original_var} ({original_units})\" if original_units else original_var\n",
    "    \n",
    "    # Use log_file name as title\n",
    "    title = log_file\n",
    "\n",
    "    # Create time series plots with modern colors\n",
    "    original_plot = original_series.hvplot.line(label='Original', color='#2E86AB', width=900, height=400, ylabel=ylabel, title=title)\n",
    "    combined_plot = combined_ds[variable_name].hvplot.line(x=combined_time_coord, label='Combined', color='#E63946', width=900, height=400, ylabel=ylabel, title=title)\n",
    "\n",
    "    logger.debug(\"Plots created successfully\")\n",
    "    \n",
    "    # Overlay the plots on the same axes\n",
    "    return original_plot * combined_plot\n",
    "\n",
    "# Select multiple variables to plot from the combined dataset\n",
    "variable_picker = widgets.SelectMultiple(\n",
    "    options=[var for var in combined_ds.data_vars],\n",
    "    description='Variables:',\n",
    "    disabled=False,\n",
    "    rows=15,\n",
    "    layout=widgets.Layout(width='800px')\n",
    ")\n",
    "display(variable_picker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all selected variables with linked axes\n",
    "if not variable_picker.value:\n",
    "    print(\"No variables selected\")\n",
    "else:\n",
    "    plots = []\n",
    "    for variable_name in variable_picker.value:\n",
    "        plot = plot_original_vs_combined(variable_name)\n",
    "        plots.append(plot)\n",
    "    \n",
    "    # Stack plots vertically with shared axes for synchronized zoom/pan\n",
    "    display(hv.Layout(plots).cols(1).opts(shared_axes=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auv-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
