{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot combined variables against original data \n",
    "To run this Notebook follow instructions at https://github.com/mbari-org/auv-python.\n",
    "\n",
    "Processed files must be available locally. Execute `uv run src/data/process_lrauv.py` with the `--no_cleanup` option to create them,e.g.:\n",
    "```\n",
    "src/data/process_lrauv.py -v --log_file pontus/missionlogs/2024/20240715_20240725/20240723T023501/202407230235_202407232319.nc4 --no_cleanup\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src/data'));\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import netCDF4 as nc4\n",
    "import logging\n",
    "from nc42netcdfs import BASE_LRAUV_PATH\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Change to logging.DEBUG for more detailed output\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Enable bokeh extension for hvplot\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Get time coordinate for each variable by introspection\n",
    "def get_time_coord(var):\n",
    "    \"\"\"Get the time coordinate name for a variable.\n",
    "    \n",
    "    Args:\n",
    "        var: Either an xarray.DataArray or netCDF4.Variable\n",
    "        \n",
    "    Returns:\n",
    "        str: Name of the time coordinate/dimension\n",
    "    \"\"\"\n",
    "    # Check if it's an xarray DataArray (has .dims attribute)\n",
    "    if hasattr(var, 'dims'):\n",
    "        # xarray DataArray\n",
    "        time_dims = [dim for dim in var.dims if 'time' in dim.lower()]\n",
    "        return time_dims[0] if time_dims else var.dims[0]\n",
    "    elif hasattr(var, 'dimensions'):\n",
    "        # netCDF4 Variable\n",
    "        time_dims = [dim for dim in var.dimensions if 'time' in dim.lower()]\n",
    "        return time_dims[0] if time_dims else var.dimensions[0]\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported variable type: {type(var)}\")\n",
    "\n",
    "# Pick the auv_name\n",
    "auv_name = widgets.Dropdown(\n",
    "    options=[f for f in sorted(os.listdir(BASE_LRAUV_PATH)) if f != \".DS_Store\"],\n",
    "    description='auv_name:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(auv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the log file from the selected LRAUV directory\n",
    "# Pattern: {lrauv_name}/missionlogs/{year}/{date_range}/{mission_start}/{log_file}.nc4\n",
    "\n",
    "lrauv_name = auv_name.value\n",
    "log_files = sorted(Path(BASE_LRAUV_PATH).glob(f\"{lrauv_name}/missionlogs/*/*/*/*[0-9].nc4\"))\n",
    "log_file_options = [str(f.relative_to(BASE_LRAUV_PATH)) for f in log_files]\n",
    "\n",
    "log_file_picker = widgets.Select(\n",
    "    options=log_file_options,\n",
    "    description='Log File:',\n",
    "    disabled=False,\n",
    "    rows=15,\n",
    "    layout=widgets.Layout(width='800px')\n",
    ")\n",
    "display(log_file_picker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all Group .nc files produced by nc42netcdfs.py for the selected log file\n",
    "log_file = log_file_picker.value\n",
    "log_path = Path(BASE_LRAUV_PATH) / log_file\n",
    "log_stem = log_path.stem\n",
    "log_dir = log_path.parent\n",
    "\n",
    "# Pattern: {log_stem}_Group_{GroupName}.nc\n",
    "group_files = sorted(log_dir.glob(f\"{log_stem}_Group_*.nc\"))\n",
    "\n",
    "# Create dictionary keyed by converted group name (remove underscores and lowercase)\n",
    "group_file_dict = {}\n",
    "for group_file in group_files:\n",
    "    # Extract group name from filename: {log_stem}_Group_{GroupName}.nc\n",
    "    group_name = group_file.stem.split(\"_Group_\")[1]\n",
    "    # Apply same transformation as group_name_mapping: remove underscores and lowercase\n",
    "    group_file_dict[group_name.replace(\"_\", \"\").lower()] = group_file\n",
    "\n",
    "logger.debug(f\"Found {len(group_file_dict)} extracted group files for {log_file}:\")\n",
    "for group_name, file_path in sorted(group_file_dict.items()):\n",
    "    logger.debug(f\"  {group_name} -> {file_path.name}\")\n",
    "\n",
    "# Read the log_file and the corresponding combined netCDF files into xarray Datasets\n",
    "combined_file = log_file.replace('.nc4', '_combined.nc4')\n",
    "\n",
    "# Open log file with all groups\n",
    "log_nc = nc4.Dataset(os.path.join(BASE_LRAUV_PATH, log_file))\n",
    "logger.debug(\"Log file: \" + os.path.join(BASE_LRAUV_PATH, log_file))\n",
    "log_ds = xr.open_dataset(os.path.join(BASE_LRAUV_PATH, log_file))\n",
    "\n",
    "# Show root group details only in DEBUG mode\n",
    "if logger.isEnabledFor(logging.DEBUG):\n",
    "    logger.debug(\"Only root group (universals):\")\n",
    "    display(log_ds)\n",
    "\n",
    "# Create dictionary mapping converted group names to original group names\n",
    "# Conversion logic from combine.py: remove underscores and lowercase\n",
    "group_name_mapping = {\n",
    "    group.replace(\"_\", \"\").lower(): group\n",
    "    for group in log_nc.groups.keys()\n",
    "}\n",
    "logger.debug(\"Group name mapping (converted -> original) with extracted NetCDF3 file listed underneath.\")\n",
    "logger.debug(\"File is created for items put into the SCIENG_PARMS group in the nc42netcdfs.py script: \")\n",
    "logger.debug(\"\")\n",
    "for converted, original in sorted(group_name_mapping.items()):\n",
    "    logger.debug(f\"{converted} -> {original}\")\n",
    "    if converted in group_file_dict:\n",
    "        logger.debug(f\"File: {group_file_dict[converted]}\")\n",
    "logger.debug(\"\")\n",
    "\n",
    "combined_ds = xr.open_dataset(os.path.join(BASE_LRAUV_PATH, combined_file))\n",
    "\n",
    "# Show combined dataset details only in DEBUG mode\n",
    "if logger.isEnabledFor(logging.DEBUG):\n",
    "    logger.debug(\"\\nCombined file: \" + os.path.join(BASE_LRAUV_PATH, combined_file))\n",
    "    display(combined_ds)\n",
    "\n",
    "def plot_nudged_position(variable_name):\n",
    "    \"\"\"Plot nudged_longitude or nudged_latitude against GPS fixes and universals.\n",
    "    \n",
    "    Shows the relationship between:\n",
    "    - universals (dead-reckoned positions)\n",
    "    - nal9602 GPS fixes\n",
    "    - nudged (corrected positions)\n",
    "    \n",
    "    Args:\n",
    "        variable_name: Either 'nudged_longitude' or 'nudged_latitude'\n",
    "        \n",
    "    Returns:\n",
    "        Overlay plot of universals, GPS fixes, and nudged data\n",
    "    \"\"\"\n",
    "    # Extract coordinate name (longitude or latitude)\n",
    "    coord_name = variable_name.split('_')[1]  # 'longitude' or 'latitude'\n",
    "    \n",
    "    universals_var = f'universals_{coord_name}'\n",
    "    gps_var = f'nal9602_{coord_name}_fix'\n",
    "    \n",
    "    logger.debug(f\"Plotting nudged position: {variable_name}\")\n",
    "    logger.debug(f\"Using: {universals_var}, {gps_var}, {variable_name}\")\n",
    "    \n",
    "    # Get time coordinates\n",
    "    universals_time_coord = get_time_coord(combined_ds[universals_var])\n",
    "    nudged_time_coord = get_time_coord(combined_ds[variable_name])\n",
    "    \n",
    "    # Get units for ylabel\n",
    "    try:\n",
    "        units = combined_ds[variable_name].attrs.get('units', '')\n",
    "    except AttributeError:\n",
    "        units = ''\n",
    "    \n",
    "    ylabel = f\"{coord_name} ({units})\" if units else coord_name\n",
    "    \n",
    "    # Create plots with distinct colors for position data\n",
    "    universals_plot = combined_ds[universals_var].hvplot.line(\n",
    "        x=universals_time_coord, \n",
    "        label='Universals (Dead Reckoned)', \n",
    "        color='#007BFF',  # Blue\n",
    "        width=900, \n",
    "        height=400, \n",
    "        ylabel=ylabel, \n",
    "        title=log_file, \n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Check if GPS fix variable exists\n",
    "    if gps_var in combined_ds:\n",
    "        gps_time_coord = get_time_coord(combined_ds[gps_var])\n",
    "        gps_plot = combined_ds[gps_var].hvplot.scatter(\n",
    "            x=gps_time_coord, \n",
    "            label='GPS Fixes', \n",
    "            color='#FFC107',  # Yellow\n",
    "            width=900, \n",
    "            height=400, \n",
    "            ylabel=ylabel, \n",
    "            title=log_file, \n",
    "            alpha=0.9,\n",
    "            size=50\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(f\"GPS fix variable {gps_var} not found - skipping GPS plot\")\n",
    "        gps_plot = None\n",
    "    \n",
    "    nudged_plot = combined_ds[variable_name].hvplot.line(\n",
    "        x=nudged_time_coord, \n",
    "        label='Nudged', \n",
    "        color='#DC3545',  # Red\n",
    "        width=900, \n",
    "        height=400, \n",
    "        ylabel=ylabel, \n",
    "        title=log_file, \n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    logger.debug(\"Position plots created successfully\")\n",
    "    \n",
    "    # Overlay plots (GPS as scatter on top for visibility)\n",
    "    # Set legend inside the plot area\n",
    "    if gps_plot:\n",
    "        return (universals_plot * nudged_plot * gps_plot).opts(legend_position='top_right')\n",
    "    else:\n",
    "        return (universals_plot * nudged_plot).opts(legend_position='top_right')\n",
    "\n",
    "def plot_original_vs_combined(variable_name):\n",
    "    \"\"\"Plot a variable from both original group and combined file overlaid.\n",
    "    \n",
    "    Args:\n",
    "        variable_name: Name of the variable from combined dataset (format: {group}_{variable})\n",
    "        \n",
    "    Returns:\n",
    "        Overlay plot of original and combined data\n",
    "    \"\"\"\n",
    "    # Check for nudged longitude/latitude - special case\n",
    "    if variable_name in ('nudged_longitude', 'nudged_latitude'):\n",
    "        return plot_nudged_position(variable_name)\n",
    "    \n",
    "    # Parse variable name to extract converted group name and original variable name\n",
    "    # Format: {converted_group}_{original_variable}\n",
    "    parts = variable_name.split('_', 1)\n",
    "    converted_group = parts[0]\n",
    "    original_var = parts[1] if len(parts) > 1 else variable_name\n",
    "\n",
    "    # Map back to original group name\n",
    "    original_group = group_name_mapping.get(converted_group, converted_group)\n",
    "\n",
    "    logger.debug(f\"Processing variable: {variable_name}\")\n",
    "    logger.debug(f\"Converted group: {converted_group}, Original group: {original_group}\")\n",
    "\n",
    "    # Get the original group dataset from log_nc\n",
    "    # Root group (universals) is accessed directly as log_nc, not through .groups\n",
    "    if original_group == \"universals\":\n",
    "        group_ds = log_nc\n",
    "    else:\n",
    "        group_ds = log_nc.groups[original_group]\n",
    "\n",
    "    # Find the original variable from the group in log_file ignoring case\n",
    "    original_var_lower = original_var.lower()\n",
    "    matching_vars = [var for var in group_ds.variables if var.lower() == original_var_lower]\n",
    "    if matching_vars:\n",
    "        original_var = matching_vars[0]\n",
    "    logger.debug(f\"Original variable: {original_var}\")\n",
    "\n",
    "    logger.debug(f\"Plotting '{original_var}' from group '{original_group}' vs combined variable '{variable_name}'\")\n",
    "\n",
    "    # Get time coordinates\n",
    "    original_time_coord = get_time_coord(group_ds.variables[original_var])\n",
    "    combined_time_coord = get_time_coord(combined_ds[variable_name])\n",
    "    logger.debug(f\"Time coords - Original: {original_time_coord}, Combined: {combined_time_coord}\")\n",
    "\n",
    "    # Extract data from netCDF4 as numpy arrays\n",
    "    original_time_data = group_ds.variables[original_time_coord][:]\n",
    "    original_var_data = group_ds.variables[original_var][:]\n",
    "    logger.debug(f\"Data shape - Original: {original_var_data.shape}, time: {original_time_data.shape}\")\n",
    "\n",
    "    # Convert Unix timestamps to datetime64 to match combined file format\n",
    "    original_time_datetime = pd.to_datetime(original_time_data, unit='s')\n",
    "    original_series = pd.Series(original_var_data, index=original_time_datetime, name=f'{original_var} (Original)')\n",
    "\n",
    "    # Read from individual group file (use lowercase converted_group as key)\n",
    "    group_file_path = group_file_dict[converted_group]\n",
    "    logger.debug(f\"Reading from group file: {group_file_path}\")\n",
    "    group_file_ds = xr.open_dataset(group_file_path)\n",
    "    group_file_time_coord = get_time_coord(group_file_ds[original_var])\n",
    "    logger.debug(f\"Group file time coordinate: {group_file_time_coord}\")\n",
    "\n",
    "    # Get units for ylabel\n",
    "    try:\n",
    "        original_units = group_ds.variables[original_var].getncattr('units')\n",
    "    except AttributeError:\n",
    "        original_units = ''\n",
    "    \n",
    "    # Create ylabel with format \"name (units)\"\n",
    "    ylabel = f\"{original_var} ({original_units})\" if original_units else original_var\n",
    "    \n",
    "    # Create time series plots with bold colors and transparency for blending\n",
    "    # Use pandas Series for original (with datetime index), xarray for others (with explicit time coord)\n",
    "    original_plot = original_series.hvplot.line(label='Original', color='#007BFF', width=900, height=400, ylabel=ylabel, title=log_file, alpha=0.7)\n",
    "    group_file_plot = group_file_ds[original_var].hvplot.line(x=group_file_time_coord, label='Group File', color='#FFC107', width=900, height=400, ylabel=ylabel, title=log_file, alpha=0.7)\n",
    "    combined_plot = combined_ds[variable_name].hvplot.line(x=combined_time_coord, label='Combined', color='#DC3545', width=900, height=400, ylabel=ylabel, title=log_file, alpha=0.7)\n",
    "    \n",
    "    logger.debug(\"Plots created successfully\")\n",
    "    \n",
    "    # Overlay the plots on the same axes (order determines legend order: Original, Group File, Combined)\n",
    "    return original_plot * group_file_plot * combined_plot\n",
    "\n",
    "# Select multiple variables to plot from the original, group file, and combined datasets\n",
    "variable_picker = widgets.SelectMultiple(\n",
    "    options=sorted([var for var in combined_ds.data_vars]),\n",
    "    description='Variables:',    disabled=False,    rows=15,    layout=widgets.Layout(width='800px'))\n",
    "display(variable_picker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all selected variables with linked axes\n",
    "plots = []\n",
    "for variable_name in variable_picker.value:\n",
    "    plot = plot_original_vs_combined(variable_name)\n",
    "    plots.append(plot)\n",
    "display(hv.Layout(plots).cols(1).opts(shared_axes=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auv-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
